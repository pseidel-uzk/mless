{
 "cells": [
  {
        "cell_type": "markdown",
        "metadata": {
          "id": "view-in-github",
          "colab_type": "text"
        },
        "source": [
          "<a href=\"https://colab.research.google.com/github/maschu09/mless/blob/main/time_series_forecasting/1_Download_Preprocess_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
        ]
    },
  {
        "cell_type": "markdown",
        "id": "93fb8933",
        "metadata": {
          "id": "93fb8933"
        },
        "source": [
          "# Data download and preparation\n",
          "\n",
          "In the following, we will set-up a typical data preprocessing workflow for (environmental) timeseries data. It is quite common that such data can be obtained via a web interface (REST API) and that the output from this API requires substantial reformatting and rearranging before the data can be imported into analysis or forecasting models. Typical issues encountered include:\n",
          "* time series at different stations (and for different parameters) vary in length\n",
          "* timeseries have some or many missing values, which are either absent from the data series or encoded as special values\n",
          "* data vary in quality (some datasets may have jumps or awkward \"features\" that cannot be explained by natural phenomena)\n",
          "* metadata to inform the data selection are missing ort difficult to access/process\n",
          "\n",
          "In this notebook, we try to keep things relatively simple and straightforward while providing a set of tools that can also be used in more meaningful applications.\n",
          "\n",
          "The default use case on which this notebook builds is to extract timeseries of the variable \"temperature\" from a handful of measurement locations, store intermediate results to avoid repeated downloads, and package the data into a single CSV file for input in the statistical analyses and ML models shown in the subsequent notebooks. The code will also run if you extract several variables at once or increase the number of stations. However, for massive data downloads, you will need to rewrite the code to be more efficient and add some monitoring of your downloads.\n",
          "\n",
          "> Please note: In case of runtime loss or a need to run any segmented sections of the code make sure to run all the housekeeping cells before it\n",
          "\n",
          "\n",
          "\n",
          "\n"
        ]
  },
  {
      "cell_type": "markdown",
      "id": "13766b33",
      "metadata": {
        "id": "13766b33"
      },
      "source": [
        "## Initial Setup and Data download\n",
        "> This section downloads example data from TOAR for 5 stations in Germany. Refer to [TOAR Quick UserGuide](https://toar-data.fz-juelich.de/sphinx/TOAR_UG_Vol02_Quick_Start/build/html/examples.html) examples to better understand data structuring in TOAR that is used in the below snippet to download examples.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/maschu09/mless/blob/main/time_series_forecasting/TOARFetchingBlockDiag.png?raw=1\" alt=\"TOAR Block Diag\" width=\"600\"/>\n",
        "</p>\n"
      ]
    },
  {
      "cell_type": "markdown",
      "id": "49eb9d93",
      "metadata": {
        "id": "49eb9d93"
      },
      "source": [
        "### Housekeeping: Initial setup, declarations and method definitions\n",
        "\n",
        "\n"
      ]
    },
      
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb98c436",
      "metadata": {
        "id": "cb98c436",
        "outputId": "a3a3731b-6598-48a3-c980-88a2897cdf25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.1.3)\n",
            "Requirement already satisfied: requests in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.32.3)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (80.7.1)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.9.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sindhu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
            "Installing collected packages: tensorflow\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Sindhu\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\com_github_grpc_grpc\\\\src\\\\core\\\\ext\\\\filters\\\\client_channel\\\\lb_policy\\\\grpclb\\\\client_load_reporting_filter.h'\n",
            "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Most notebook servers like google collab should have these packages pre-installed\n",
        "# In such cases this is just a sanity check\n",
        "!pip install pandas numpy requests tensorflow"
      ]
    },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4eba776",
   "metadata": {
    "id": "b4eba776"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Global constants\n",
    "TIMESERIES_DATA_DIR = \"./content/timeseries_data/\"\n",
    "TIMESERIES_CSV_DIR = os.path.join(TIMESERIES_DATA_DIR, \"toar_csv_timeseries\")\n",
    "TIMESERIES_ID_FILE = os.path.join(TIMESERIES_DATA_DIR, \"timeseriesIDs.json\")\n",
    "MIN_FILE_SIZE_BYTES = 100\n",
    "group_columns = ['station_code', 'latitude', 'longitude']\n",
    "\n",
    "os.makedirs(TIMESERIES_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TIMESERIES_CSV_DIR, exist_ok=True)"
   ]
  },
  {
      "cell_type": "markdown",
      "id": "46af26a1",
      "metadata": {
        "id": "46af26a1"
      },
      "source": [
        "### Custom data selection for experiments\n",
        "\n",
        "The station codes in the example snippet below are checked for a common daterange for the chosen variables and offer reasonably complete timeseries. If you prefer to experiment with other datasets, consult the documentation on the [Search API](https://toar-data.fz-juelich.de/api/v2/#search-combined-endpoint-of-stations-and-timeseries).\n",
        "\n",
        "ðŸ˜ˆ **Question 1:** What are common reasons for gaps in observational data records, such as from TOAR?\n"
      ]
    },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663fef6",
   "metadata": {
    "id": "9663fef6"
   },
   "outputs": [],
   "source": [
    "# German stations with good distribution temp variable observations\n",
    "station_codes = [\"DENW094\", \"DEBW073\",\"DEHE020\"]\n",
    "variable_columns = [\"temp\"]\n",
    "# station_codes = [\"DENW094\"]\n",
    "# variable_columns = [\"no2\", \"temp\", \"o3\", \"no\", \"press\"]\n"
   ]
  },
  {
      "cell_type": "markdown",
      "id": "70d99569",
      "metadata": {
        "id": "70d99569"
      },
      "source": [
        "ðŸ˜ˆ **Task 1:** Explore the `station_codes` variable and try changing the station(s) to a different region.\n",
        "\n",
        "Below methods each have appropriate documentation and comments to illustrate the logical flow *(they are placed with enough safeguards against both the API and optimized to avoid re-downloads when interupted during partial downloads to accomodate any loss of runtime on platforms like google colab)* and briefly described here for ease of use\n",
        "\n",
        "ðŸ˜ˆ **Task 2:** Inspect the function `pivot_handle()`. What does it return, and why is pivoting important for time series analysis?\n"
      ]
    },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2eebb7",
   "metadata": {
    "id": "ef2eebb7"
   },
   "outputs": [],
   "source": [
    "def load_existing_timeseries_ids():\n",
    "    \"\"\"\n",
    "    Load existing timeseries IDs from a JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing stored timeseries metadata.\n",
    "    \"\"\"\n",
    "    return json.load(open(TIMESERIES_ID_FILE, 'r')) if os.path.exists(TIMESERIES_ID_FILE) else {}\n",
    "\n",
    "def save_timeseries_ids(timeseries_data):\n",
    "    \"\"\"\n",
    "    Save timeseries metadata to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        timeseries_data (dict): A dictionary containing timeseries metadata.\n",
    "    \"\"\"\n",
    "    json.dump(timeseries_data, open(TIMESERIES_ID_FILE, 'w'), indent=4)\n",
    "\n",
    "def fetch_timeseries_data(station_codes, existing_timeseries, variable_columns):\n",
    "    \"\"\"\n",
    "    Fetch timeseries metadata for given station codes, filtering by specified variables.\n",
    "\n",
    "    Args:\n",
    "        station_codes (list): List of station codes to fetch data for.\n",
    "        existing_timeseries (dict): Dictionary of previously fetched timeseries metadata.\n",
    "        variable_columns (list): List of variable names to retain.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated dictionary containing filtered timeseries metadata.\n",
    "    \"\"\"\n",
    "    base_url = \"http://toar-data.fz-juelich.de/api/v2/search/?codes=\"\n",
    "    unique_entries = existing_timeseries.copy()\n",
    "    processed_station_codes = {details['station_code'] for details in existing_timeseries.values()}\n",
    "\n",
    "    for code in station_codes:\n",
    "        if code in processed_station_codes:\n",
    "            print(f\"\\t\\tStation {code} is already processed, skipping.\")\n",
    "            continue\n",
    "\n",
    "        response = requests.get(base_url + code, timeout=1000)\n",
    "        if response.status_code == 200:\n",
    "            for entry in response.json():\n",
    "                if (variable_name := entry.get('variable', {}).get('name')) in variable_columns:\n",
    "                    timeseries_id = entry.get('id')\n",
    "                    if timeseries_id not in unique_entries:\n",
    "                        unique_entries[timeseries_id] = {\n",
    "                            'data_start_date': entry.get('data_start_date'),\n",
    "                            'data_end_date': entry.get('data_end_date'),\n",
    "                            'variable_name': variable_name,\n",
    "                            'station_code': code,\n",
    "                            'latitude': entry.get('station', {}).get('coordinates', {}).get('lat'),\n",
    "                            'longitude': entry.get('station', {}).get('coordinates', {}).get('lng'),\n",
    "                        }\n",
    "        else:\n",
    "            print(f\"\\t\\tFailed to fetch data for station {code}. Status code: {response.status_code}\")\n",
    "    return unique_entries\n",
    "\n",
    "def pivot_handle(dfs, metadata_columns, variable_columns):\n",
    "    \"\"\"\n",
    "    Pivot and structure the timeseries dataframe for sequential data analysis.\n",
    "\n",
    "    Args:\n",
    "        dfs (pd.DataFrame): Dataframe containing timeseries data.\n",
    "        metadata_columns (list): List of metadata column names.\n",
    "        variable_columns (list): List of variable names to include.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed dataframe with pivoted structure.\n",
    "    \"\"\"\n",
    "    pivot_df = dfs.pivot_table(index='datetime', columns='variable_name', values='value', aggfunc='mean')\n",
    "    pivot_df.reset_index(inplace=True)\n",
    "\n",
    "    print(f\"Station {dfs['station_code'].unique()} min time: {dfs['datetime'].min()}, max time: {dfs['datetime'].max()}, hours between: {(dfs['datetime'].max() - dfs['datetime'].min()) / pd.Timedelta(hours=1):.2f}\")\n",
    "    reference_index = pd.date_range(start=dfs['datetime'].min(), end=dfs['datetime'].max(), freq=\"h\", tz=\"UTC\")\n",
    "    reference_df = pd.DataFrame({'datetime': reference_index})\n",
    "\n",
    "    pivot_df_ = reference_df.merge(pivot_df, on='datetime', how='left')\n",
    "\n",
    "    for col in metadata_columns:\n",
    "        if dfs[col].notna().any():\n",
    "            value = dfs[col].dropna().iloc[0]\n",
    "            pivot_df_.insert(0, col, value)\n",
    "        else:\n",
    "            print(f\"Station {dfs['station_code'].unique()}: metadata {col} has no value\")\n",
    "\n",
    "    return pivot_df_\n",
    "\n",
    "def download_csv_data(timeseries_data, variable_columns):\n",
    "    \"\"\"\n",
    "    Download and process CSV data for each timeseries ID.\n",
    "\n",
    "    Args:\n",
    "        timeseries_data (dict): Dictionary containing timeseries metadata.\n",
    "        variable_columns (list): List of variable names to process.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined dataframe of all timeseries data.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    metadata_columns = ['station_code', 'latitude', 'longitude']\n",
    "\n",
    "    for ts_id, details in timeseries_data.items():\n",
    "        csv_path = os.path.join(TIMESERIES_CSV_DIR, f\"{ts_id}.csv\")\n",
    "\n",
    "        if os.path.exists(csv_path) and os.path.getsize(csv_path) > MIN_FILE_SIZE_BYTES:\n",
    "            print(f\"\\tCSV already exists for timeseries ID {ts_id}, skipping download.\")\n",
    "        else:\n",
    "            print(f\"\\tDownloading data for timeseries ID {ts_id}\")\n",
    "            url = f\"http://toar-data.fz-juelich.de/api/v2/data/timeseries/{ts_id}?format=csv\"\n",
    "            try:\n",
    "                response = requests.get(url, stream=True, timeout=1000)\n",
    "                response.raise_for_status()\n",
    "                with open(csv_path, 'wb') as file:\n",
    "                    file.writelines(response.iter_content(chunk_size=8192))\n",
    "                print(f\"\\t\\tRaw data CSV of {ts_id} saved: {csv_path}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"\\t\\tFailed to download data for timeseries ID {ts_id}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, skiprows=lambda i: i < next(i for i, line in enumerate(open(csv_path)) if line.startswith('datetime')), low_memory=False)\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'], format='mixed')\n",
    "            df[['variable_name', 'station_code', 'latitude', 'longitude']] = details['variable_name'], details['station_code'], details['latitude'], details['longitude']\n",
    "            print(f\"Dataframe for timeseries ID {ts_id} loaded successfully with shape {df.shape}\")\n",
    "            dataframes.append(pivot_handle(df, metadata_columns, variable_columns))\n",
    "        except (pd.errors.EmptyDataError, pd.errors.ParserError) as e:\n",
    "            print(f\"\\tError processing CSV for timeseries ID {ts_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.concat(dataframes, ignore_index=True).sort_values(by=['station_code', 'datetime']) if dataframes else pd.DataFrame()"
   ]
  },
  {
      "cell_type": "markdown",
      "id": "6dab0925",
      "metadata": {
        "id": "6dab0925"
      },
      "source": [
        "### Download via REST API\n",
        "\n",
        "ðŸ˜ˆ **Task 3:** Try downloading a different variable or add another pollutant (e.g., `so2`). What changes?\n"
      ]
    },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3464c4",
   "metadata": {
    "id": "5c3464c4",
    "outputId": "32aa6df6-b53a-47c9-f150-dca20e15ce0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tStation DENW094 is already processed, skipping.\n",
      "\t\tStation DEBW073 is already processed, skipping.\n",
      "\t Number of time series meta data fetched : 3\n",
      "\tCSV already exists for timeseries ID 76, skipping download.\n",
      "Dataframe for timeseries ID 76 loaded successfully with shape (245580, 9)\n",
      "Station ['DENW094'] min time: 1997-01-01 00:00:00+00:00, max time: 2025-05-16 11:00:00+00:00, hours between: 248699.00\n",
      "\tCSV already exists for timeseries ID 22639, skipping download.\n",
      "Dataframe for timeseries ID 22639 loaded successfully with shape (110890, 9)\n",
      "Station ['DEBW073'] min time: 1997-01-01 00:00:00+00:00, max time: 2011-12-31 23:00:00+00:00, hours between: 131471.00\n",
      "\tCSV already exists for timeseries ID 18022, skipping download.\n",
      "Dataframe for timeseries ID 18022 loaded successfully with shape (219901, 9)\n",
      "Station ['DEHE020'] min time: 1997-01-01 00:00:00+00:00, max time: 2025-05-16 11:00:00+00:00, hours between: 248699.00\n",
      "\t Total dataFrames processed : 628872 and shape of first dataframe (628872, 5).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>station_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248700</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248701</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248702</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248703</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>-12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248704</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>-12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        longitude   latitude station_code                  datetime  temp\n",
       "248700   7.567796  47.819182      DEBW073 1997-01-01 00:00:00+00:00 -10.0\n",
       "248701   7.567796  47.819182      DEBW073 1997-01-01 01:00:00+00:00 -11.0\n",
       "248702   7.567796  47.819182      DEBW073 1997-01-01 02:00:00+00:00 -11.0\n",
       "248703   7.567796  47.819182      DEBW073 1997-01-01 03:00:00+00:00 -12.0\n",
       "248704   7.567796  47.819182      DEBW073 1997-01-01 04:00:00+00:00 -12.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing timeseries IDs from json to skip calls to TOAR\n",
    "existing_timeseries = load_existing_timeseries_ids()\n",
    "\n",
    "timeseries_data = fetch_timeseries_data(station_codes, existing_timeseries,variable_columns)\n",
    "print(f\"\\t Number of time series meta data fetched : {len(timeseries_data)}\")\n",
    "\n",
    "# save existing timeseries IDs as json to reduce calls to TOAR in future\n",
    "save_timeseries_ids(timeseries_data)\n",
    "\n",
    "dataframes = download_csv_data(timeseries_data,variable_columns)\n",
    "print(f\"\\t Total dataFrames processed : {len(dataframes)} and shape of first dataframe {dataframes.shape}.\")\n",
    "\n",
    "dataframes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8d25f",
   "metadata": {
    "id": "86c8d25f"
   },
   "source": [
        "Most of the data in TOAR is observational data which has few or many data gaps. The \"temp\"(erature) data that you downloaded is actually from a model (ERA5 reanalysis) and should therefore not have any missing values (except if your requested daterange extends beyond the period for which we extracted ERA5 data).\n",
        "\n",
        "To demonstrate a more typical workflow of handling observational data, we will now inspect, interpolate, and remove missing data values. Note that the pivot routine above merged data from different variables together and introduced NaNs."
      ]
  },
  {
   "cell_type": "markdown",
   "id": "2588a2f2",
   "metadata": {
    "id": "2588a2f2"
   },
   "source": [
        "## Data handling (observational gaps)\n",
        "\n",
        "ðŸ˜ˆ **Task 4:** Insert some code to find out how many NaN values each variable in the dataset contains. Even better: try to generate a bargraph showing the number of instances with consecutive NaN values (1, 2, 3, ..., more than 10).\n",
        "\n",
        "To provide as much training data to ML models as possible, you typically want to fill gaps through interpolation. For environmental data, it is common practice to interpolate over up to 6 hours but not longer. In many cases, linear interpolation will work just fine.\n",
        "\n",
        "\n",
        "ðŸ˜ˆ **Question 3:** Why is it acceptable to fill up to 6 missing hourly values in this dataset?\n",
        "\n",
        "ðŸ˜ˆ **Question 4:** Why do you need to interpolate at all? Wouldn't it be sufficient to randomly sample from the existing data?\n"
      ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0237f955",
   "metadata": {
    "id": "0237f955"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def fill_six_nans(group):\n",
    "    \"\"\"\n",
    "    Fills up to six consecutive NaN values in a given pandas Series using linear interpolation\n",
    "    if the NaNs are surrounded by valid values. If the NaNs are at the start, they are replaced\n",
    "    with zeros, and if they are at the end, they are filled with the last known value.\n",
    "\n",
    "    Args:\n",
    "        group (pd.Series): The input Series with potential NaN values.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series where up to six consecutive NaNs are interpolated, and longer NaN\n",
    "        sequences are partially filled while preserving the original index.\n",
    "    \"\"\"\n",
    "    values = group.to_numpy()\n",
    "    i = 0\n",
    "    while i < len(values):\n",
    "        if np.isnan(values[i]):\n",
    "            start = i\n",
    "            while i < len(values) and np.isnan(values[i]):\n",
    "                i += 1\n",
    "            end = min(i, start + 6)  # Limit to filling only 6 NaNs\n",
    "\n",
    "            if start > 0 and i < len(values):  # NaNs in the middle\n",
    "                fill_values = np.linspace(values[start - 1], values[i], end - start + 2)[1:-1]\n",
    "            elif start == 0:  # NaNs at the start\n",
    "                fill_values = [0] * (end - start)\n",
    "            elif i >= len(values):  # NaNs at the end\n",
    "                fill_values = [values[start - 1]] * (end - start)\n",
    "            values[start:end] = fill_values\n",
    "        else:\n",
    "            i += 1\n",
    "    return pd.Series(values, index=group.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d861e5dd",
   "metadata": {
    "id": "d861e5dd",
    "outputId": "72ec71f5-cdce-4dc1-d694-f446894d9f34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude           0\n",
       "latitude            0\n",
       "station_code        0\n",
       "datetime            0\n",
       "temp            50056\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[variable_columns] = dataframes.groupby(group_columns)[variable_columns].transform(fill_six_nans)\n",
    "dataframes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c220f",
   "metadata": {
    "id": "c67c220f"
   },
   "source": [
        "Now rest of the Nas can be dropped as that station might not have data collected in the time period and the data needs to be normalized.\n",
        "\n",
        "ðŸ˜ˆ **Question 5:** What risks might arise if normalization is applied *before* handling missing values?\n"
      ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079160de",
   "metadata": {
    "id": "079160de",
    "outputId": "df195013-3e82-4da9-ee31-810829f430f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude       0\n",
       "latitude        0\n",
       "station_code    0\n",
       "datetime        0\n",
       "temp            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = dataframes.dropna()\n",
    "dataframes.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2b6ef96",
   "metadata": {
    "id": "e2b6ef96",
    "outputId": "14550138-169f-4ea7-9962-f4739424e8ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579480, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3618005c",
   "metadata": {
    "id": "3618005c"
   },
   "source": [
        "## Staged data loading (Housekeeping)\n",
        "\n",
        "Finally, and before we want to perform any analysis of the data, we will store the \"cleaned\" dataset for later re-use. Subsequent notebooks can then easily reload the \"raw_data\" from the local storage or your mounted google drive folder when needed."
      ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6e51c3f",
   "metadata": {
    "id": "e6e51c3f"
   },
   "outputs": [],
   "source": [
    "dataframes.to_csv(os.path.join(TIMESERIES_DATA_DIR, \"raw_data.csv\"), index=False)"
   ]
  },
  {
      "cell_type": "markdown",
      "source": [
        "ðŸ˜ˆ **Task 6:** Re-inspect the code above and reflect on the data management strategy employed here. What happens if you re-run the script after changing station codes or variables? Would the notebook repeat all download operations if you add a single station or variable? What could you do to improve this workflow?\n",
        "\n",
        "Don't waste time by trying to build the ultimate do-it-all dataloader - you can attend my lecture on Earth System Data Processing if you are keen to go deeper down this route."
      ],
      "metadata": {
        "id": "838444Ie5Lsr"
      },
      "id": "838444Ie5Lsr"
    },
  {
   "cell_type": "markdown",
   "id": "45c18223",
   "metadata": {
    "id": "45c18223"
   },
   "source": [
    "### Leftovers from first cleanup\n",
        "\n",
        "\n",
        "Below cell can be used to reload data if using an open source notebook servers like google colab and the if the usage limit is reached or for other issues"
      ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "626bfaba",
   "metadata": {
    "id": "626bfaba",
    "outputId": "5f845c54-d6eb-40f2-8bbf-dcc5a1138ade"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>station_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>-12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.567796</td>\n",
       "      <td>47.819182</td>\n",
       "      <td>DEBW073</td>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>-12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude   latitude station_code                  datetime  temp\n",
       "0   7.567796  47.819182      DEBW073 1997-01-01 00:00:00+00:00 -10.0\n",
       "1   7.567796  47.819182      DEBW073 1997-01-01 01:00:00+00:00 -11.0\n",
       "2   7.567796  47.819182      DEBW073 1997-01-01 02:00:00+00:00 -11.0\n",
       "3   7.567796  47.819182      DEBW073 1997-01-01 03:00:00+00:00 -12.0\n",
       "4   7.567796  47.819182      DEBW073 1997-01-01 04:00:00+00:00 -12.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## Raw data csv is also made available for the select stations in URL:\n",
    "url = \"https://drive.google.com/uc?export=download&id=1cmTTWY3f18SikgRBcZzhtFswIf7XwPJq\"\n",
    "dataframes = pd.read_csv(url,parse_dates=[\"datetime\"])\n",
    "## Else if using local files:\n",
    "# dataframes = pd.read_csv(os.path.join(TIMESERIES_DATA_DIR, \"raw_data.csv\"))\n",
    "dataframes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9d4b72a",
   "metadata": {
    "id": "b9d4b72a",
    "outputId": "558d69c8-8e4e-4df4-dd9b-9f4df088a0f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579480, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44b4e968",
   "metadata": {
    "id": "44b4e968",
    "outputId": "78e2a0da-416a-4421-dbea-8b82f6116367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime        0\n",
       "station_code    0\n",
       "latitude        0\n",
       "longitude       0\n",
       "temp            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7426db96",
   "metadata": {
    "id": "7426db96"
   },
   "source": [
    "### Statistical Analysis\n",
    "\n",
    "The data can now be analysed for basic statistical tendencies or measures like (note standard measures are indicated here, but you can run custom measures as well)\n",
    "\n",
    "ðŸ˜ˆ **Task 6:** Create a boxplot for `no2` and `o3` by station to visualize spread and outliers.\n",
    "\n",
    "ðŸ˜ˆ **Question 4:** Which station shows the highest variance in `no2`? What might explain this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1205a5d1",
   "metadata": {
    "id": "1205a5d1",
    "outputId": "e188dfcc-e1a8-4d6a-c401-315c99b5928d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"14\" halign=\"left\">temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>median</th>\n",
       "      <th>prod</th>\n",
       "      <th>nunique</th>\n",
       "      <th>5th_percentile</th>\n",
       "      <th>10th_percentile</th>\n",
       "      <th>25th_percentile</th>\n",
       "      <th>50th_percentile</th>\n",
       "      <th>75th_percentile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DEBW073</th>\n",
       "      <td>-14.50</td>\n",
       "      <td>37.300000</td>\n",
       "      <td>10.978124</td>\n",
       "      <td>1.225576e+06</td>\n",
       "      <td>8.181187</td>\n",
       "      <td>66.931819</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1437</td>\n",
       "      <td>-2.00000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEHE020</th>\n",
       "      <td>-18.20</td>\n",
       "      <td>38.842102</td>\n",
       "      <td>10.697320</td>\n",
       "      <td>2.362931e+06</td>\n",
       "      <td>8.085592</td>\n",
       "      <td>65.376801</td>\n",
       "      <td>10.224525</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>96483</td>\n",
       "      <td>-1.39341</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.604458</td>\n",
       "      <td>10.224525</td>\n",
       "      <td>16.386687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>-17.95</td>\n",
       "      <td>39.126000</td>\n",
       "      <td>10.551892</td>\n",
       "      <td>2.605811e+06</td>\n",
       "      <td>7.280977</td>\n",
       "      <td>53.012631</td>\n",
       "      <td>10.276000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51278</td>\n",
       "      <td>-0.77100</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.258750</td>\n",
       "      <td>10.276000</td>\n",
       "      <td>15.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               temp                                                           \\\n",
       "                min        max       mean           sum       std        var   \n",
       "station_code                                                                   \n",
       "DEBW073      -14.50  37.300000  10.978124  1.225576e+06  8.181187  66.931819   \n",
       "DEHE020      -18.20  38.842102  10.697320  2.362931e+06  8.085592  65.376801   \n",
       "DENW094      -17.95  39.126000  10.551892  2.605811e+06  7.280977  53.012631   \n",
       "\n",
       "                                                                     \\\n",
       "                 median prod nunique 5th_percentile 10th_percentile   \n",
       "station_code                                                          \n",
       "DEBW073       11.000000  0.0    1437       -2.00000            0.25   \n",
       "DEHE020       10.224525 -0.0   96483       -1.39341            0.60   \n",
       "DENW094       10.276000  NaN   51278       -0.77100            1.25   \n",
       "\n",
       "                                                              \n",
       "             25th_percentile 50th_percentile 75th_percentile  \n",
       "station_code                                                  \n",
       "DEBW073             4.950000       11.000000       16.800000  \n",
       "DEHE020             4.604458       10.224525       16.386687  \n",
       "DENW094             5.258750       10.276000       15.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'min'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DEBW073</th>\n",
       "      <td>-14.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEHE020</th>\n",
       "      <td>-18.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>-17.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               temp\n",
       "station_code       \n",
       "DEBW073      -14.50\n",
       "DEHE020      -18.20\n",
       "DENW094      -17.95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'max'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DEBW073</th>\n",
       "      <td>37.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEHE020</th>\n",
       "      <td>38.842102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>39.126000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   temp\n",
       "station_code           \n",
       "DEBW073       37.300000\n",
       "DEHE020       38.842102\n",
       "DENW094       39.126000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mean'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DEBW073</th>\n",
       "      <td>10.978124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEHE020</th>\n",
       "      <td>10.697320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>10.551892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   temp\n",
       "station_code           \n",
       "DEBW073       10.978124\n",
       "DEHE020       10.697320\n",
       "DENW094       10.551892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'std'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DEBW073</th>\n",
       "      <td>8.181187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEHE020</th>\n",
       "      <td>8.085592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>7.280977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  temp\n",
       "station_code          \n",
       "DEBW073       8.181187\n",
       "DEHE020       8.085592\n",
       "DENW094       7.280977"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = ['min', 'max', 'mean', 'sum', 'std', 'var', 'median','prod','nunique',\n",
    "    ('5th_percentile', lambda x: x.quantile(0.05)),\n",
    "    ('10th_percentile', lambda x: x.quantile(0.10)),\n",
    "    ('25th_percentile', lambda x: x.quantile(0.25)),\n",
    "    ('50th_percentile', lambda x: x.quantile(0.50)), #(median)\n",
    "    ('75th_percentile', lambda x: x.quantile(0.75))]\n",
    "agg_dict = {col: stats for col in variable_columns}\n",
    "grouped = dataframes.groupby('station_code').agg(agg_dict)\n",
    "display(grouped)\n",
    "\n",
    "for agg_func in ['min', 'max', 'mean', 'std']:\n",
    "    display(agg_func)\n",
    "    agg_view = grouped.xs(agg_func, axis=1, level=1)\n",
    "    display(agg_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ZLNbEWgo7c0",
   "metadata": {
    "id": "5ZLNbEWgo7c0"
   },
   "source": [
    "### (Optional/Advanced) Multi-Variable Case:\n",
    "\n",
    "We've seen how to download one variable for multiple stations. Now let's try and download multi-variables for one station.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r8CVdDesp9bq",
   "metadata": {
    "id": "r8CVdDesp9bq"
   },
   "source": [
    "- You know the drill at this point:\n",
    "  - Set the paths for loading the timeseries_ids(unique to each variable) corresponding to the station code and downloading timeseries data for all the variables.\n",
    "  - Fetch the variables for the station of interest\n",
    "  - Fill the gaps upto 6hrs\n",
    "  - Drop NAs\n",
    "  - Log transformation after checking for skewdness(additional)\n",
    "  - Z-score Normalization (for ML training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "lW06F1v7p8mJ",
   "metadata": {
    "id": "lW06F1v7p8mJ"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Global constants\n",
    "TIMESERIES_DATA_DIR = \"./content/timeseries_multivariate_data/\"\n",
    "TIMESERIES_CSV_DIR = os.path.join(TIMESERIES_DATA_DIR, \"toar_csv_timeseries\")\n",
    "TIMESERIES_ID_FILE = os.path.join(TIMESERIES_DATA_DIR, \"timeseriesIDs.json\")\n",
    "MIN_FILE_SIZE_BYTES = 100\n",
    "group_columns = ['station_code', 'latitude', 'longitude']\n",
    "\n",
    "os.makedirs(TIMESERIES_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TIMESERIES_CSV_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tVyo57nMqOd4",
   "metadata": {
    "id": "tVyo57nMqOd4"
   },
   "source": [
    "#### Fetch the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "Mk8UUqZOqN05",
   "metadata": {
    "id": "Mk8UUqZOqN05"
   },
   "outputs": [],
   "source": [
    "# German stations with good distribution o3 variable observations\n",
    "station_codes = [\"DENW094\"]\n",
    "variable_columns = [\"no2\", \"temp\", \"o3\", \"no\", \"press\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FvPc3lp8aoN9",
   "metadata": {
    "id": "FvPc3lp8aoN9"
   },
   "source": [
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BBpWNtA2pX5K",
   "metadata": {
    "id": "BBpWNtA2pX5K"
   },
   "source": [
    "#### Download the variables data for that 1 station via REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "yIGfmD85pMF7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "yIGfmD85pMF7",
    "outputId": "f69a57a6-3ef4-4cc6-b110-d7038f759867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tStation DENW094 is already processed, skipping.\n",
      "\t Number of time series meta data fetched : 5\n",
      "\tCSV already exists for timeseries ID 73, skipping download.\n",
      "Dataframe for timeseries ID 73 loaded successfully with shape (210619, 9)\n",
      "Station ['DENW094'] min time: 1999-07-02 18:00:00+00:00, max time: 2025-05-30 07:00:00+00:00, hours between: 227125.00\n",
      "\tCSV already exists for timeseries ID 74, skipping download.\n",
      "Dataframe for timeseries ID 74 loaded successfully with shape (209675, 9)\n",
      "Station ['DENW094'] min time: 1999-07-05 15:00:00+00:00, max time: 2025-05-30 07:00:00+00:00, hours between: 227056.00\n",
      "\tCSV already exists for timeseries ID 75, skipping download.\n",
      "Dataframe for timeseries ID 75 loaded successfully with shape (208155, 9)\n",
      "Station ['DENW094'] min time: 1999-07-05 15:00:00+00:00, max time: 2025-05-30 07:00:00+00:00, hours between: 227056.00\n",
      "\tCSV already exists for timeseries ID 76, skipping download.\n",
      "Dataframe for timeseries ID 76 loaded successfully with shape (245896, 9)\n",
      "Station ['DENW094'] min time: 1997-01-01 00:00:00+00:00, max time: 2025-05-30 07:00:00+00:00, hours between: 249031.00\n",
      "\tCSV already exists for timeseries ID 80, skipping download.\n",
      "Dataframe for timeseries ID 80 loaded successfully with shape (160608, 9)\n",
      "Station ['DENW094'] min time: 1999-07-02 14:00:00+00:00, max time: 2023-12-31 23:00:00+00:00, hours between: 214761.00\n",
      "\t Total dataFrames processed : 1145034 and shape of first dataframe (1145034, 9).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>station_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>o3</th>\n",
       "      <th>no2</th>\n",
       "      <th>no</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681240</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681241</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681242</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681243</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681244</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        longitude   latitude station_code                  datetime  o3  no2  \\\n",
       "681240   6.093923  50.754704      DENW094 1997-01-01 00:00:00+00:00 NaN  NaN   \n",
       "681241   6.093923  50.754704      DENW094 1997-01-01 01:00:00+00:00 NaN  NaN   \n",
       "681242   6.093923  50.754704      DENW094 1997-01-01 02:00:00+00:00 NaN  NaN   \n",
       "681243   6.093923  50.754704      DENW094 1997-01-01 03:00:00+00:00 NaN  NaN   \n",
       "681244   6.093923  50.754704      DENW094 1997-01-01 04:00:00+00:00 NaN  NaN   \n",
       "\n",
       "        no   temp  press  \n",
       "681240 NaN -15.85    NaN  \n",
       "681241 NaN -16.35    NaN  \n",
       "681242 NaN -16.45    NaN  \n",
       "681243 NaN -17.15    NaN  \n",
       "681244 NaN -17.35    NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }]
  },
  {
   "cell_type": "markdown",
   "id": "qqmumS-_pope",
   "metadata": {
    "id": "qqmumS-_pope"
   },
   "source": [
    "#### Data handling (observational gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s7xwW3dEKftO",
   "metadata": {
    "id": "s7xwW3dEKftO"
   },
   "source": [
    "##### Filling up upto 6 NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "sdTokb2GKeDH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "sdTokb2GKeDH",
    "outputId": "6b1391b2-ff69-4611-c7dd-5818c974e9d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude            0\n",
       "latitude             0\n",
       "station_code         0\n",
       "datetime             0\n",
       "o3               84547\n",
       "no2              89828\n",
       "no               96958\n",
       "temp             14185\n",
       "press           341631\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[variable_columns] = dataframes.groupby(group_columns)[variable_columns].transform(fill_six_nans)\n",
    "dataframes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3Y9nlWqmJQe2",
   "metadata": {
    "id": "3Y9nlWqmJQe2"
   },
   "source": [
    "##### After dropping NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "U5S7KBXSJOb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "U5S7KBXSJOb4",
    "outputId": "8ce3d5f1-9d18-4ab3-f49f-a15841f246fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude       0\n",
       "latitude        0\n",
       "station_code    0\n",
       "datetime        0\n",
       "o3              0\n",
       "no2             0\n",
       "no              0\n",
       "temp            0\n",
       "press           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = dataframes.dropna()\n",
    "dataframes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qd4YM9V0Smu8",
   "metadata": {
    "id": "qd4YM9V0Smu8"
   },
   "source": [
    "#### Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61S7XC7zNU1y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "61S7XC7zNU1y",
    "outputId": "f5e2396b-1dba-4be0-9bef-02bbff2c6ba8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">no2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>median</th>\n",
       "      <th>prod</th>\n",
       "      <th>nunique</th>\n",
       "      <th>5th_percentile</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>median</th>\n",
       "      <th>prod</th>\n",
       "      <th>nunique</th>\n",
       "      <th>5th_percentile</th>\n",
       "      <th>10th_percentile</th>\n",
       "      <th>25th_percentile</th>\n",
       "      <th>50th_percentile</th>\n",
       "      <th>75th_percentile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>-2.544249</td>\n",
       "      <td>81.321835</td>\n",
       "      <td>7.576288</td>\n",
       "      <td>5.309811e+06</td>\n",
       "      <td>6.360161</td>\n",
       "      <td>40.451654</td>\n",
       "      <td>5.648076</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>289712</td>\n",
       "      <td>1.25063</td>\n",
       "      <td>...</td>\n",
       "      <td>9.810325</td>\n",
       "      <td>96.242473</td>\n",
       "      <td>993.1915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170209</td>\n",
       "      <td>975.432</td>\n",
       "      <td>980.0</td>\n",
       "      <td>987.046385</td>\n",
       "      <td>993.1915</td>\n",
       "      <td>998.9072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   no2                                               \\\n",
       "                   min        max      mean           sum       std   \n",
       "station_code                                                          \n",
       "DENW094      -2.544249  81.321835  7.576288  5.309811e+06  6.360161   \n",
       "\n",
       "                                                               ...     press  \\\n",
       "                    var    median prod nunique 5th_percentile  ...       std   \n",
       "station_code                                                   ...             \n",
       "DENW094       40.451654  5.648076 -0.0  289712        1.25063  ...  9.810325   \n",
       "\n",
       "                                                                               \\\n",
       "                    var    median prod nunique 5th_percentile 10th_percentile   \n",
       "station_code                                                                    \n",
       "DENW094       96.242473  993.1915  0.0  170209        975.432           980.0   \n",
       "\n",
       "                                                              \n",
       "             25th_percentile 50th_percentile 75th_percentile  \n",
       "station_code                                                  \n",
       "DENW094           987.046385        993.1915        998.9072  \n",
       "\n",
       "[1 rows x 70 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'min'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no2</th>\n",
       "      <th>temp</th>\n",
       "      <th>o3</th>\n",
       "      <th>no</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>-2.544249</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>-1.417507</td>\n",
       "      <td>-3.360428</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   no2   temp        o3        no  press\n",
       "station_code                                            \n",
       "DENW094      -2.544249 -17.35 -1.417507 -3.360428    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'max'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no2</th>\n",
       "      <th>temp</th>\n",
       "      <th>o3</th>\n",
       "      <th>no</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>81.321835</td>\n",
       "      <td>39.0784</td>\n",
       "      <td>134.83356</td>\n",
       "      <td>447.81647</td>\n",
       "      <td>1023.717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    no2     temp         o3         no     press\n",
       "station_code                                                    \n",
       "DENW094       81.321835  39.0784  134.83356  447.81647  1023.717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mean'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no2</th>\n",
       "      <th>temp</th>\n",
       "      <th>o3</th>\n",
       "      <th>no</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>7.576288</td>\n",
       "      <td>10.68534</td>\n",
       "      <td>24.713563</td>\n",
       "      <td>3.301673</td>\n",
       "      <td>992.484116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   no2      temp         o3        no       press\n",
       "station_code                                                     \n",
       "DENW094       7.576288  10.68534  24.713563  3.301673  992.484116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'std'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no2</th>\n",
       "      <th>temp</th>\n",
       "      <th>o3</th>\n",
       "      <th>no</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>6.360161</td>\n",
       "      <td>7.440747</td>\n",
       "      <td>14.653677</td>\n",
       "      <td>8.852862</td>\n",
       "      <td>9.810325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   no2      temp         o3        no     press\n",
       "station_code                                                   \n",
       "DENW094       6.360161  7.440747  14.653677  8.852862  9.810325"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = ['min', 'max', 'mean', 'sum', 'std', 'var', 'median','prod','nunique',\n",
    "    ('5th_percentile', lambda x: x.quantile(0.05)),\n",
    "    ('10th_percentile', lambda x: x.quantile(0.10)),\n",
    "    ('25th_percentile', lambda x: x.quantile(0.25)),\n",
    "    ('50th_percentile', lambda x: x.quantile(0.50)), #(median)\n",
    "    ('75th_percentile', lambda x: x.quantile(0.75))]\n",
    "agg_dict = {col: stats for col in variable_columns}\n",
    "grouped = dataframes.groupby('station_code').agg(agg_dict)\n",
    "display(grouped)\n",
    "\n",
    "for agg_func in ['min', 'max', 'mean', 'std']:\n",
    "    display(agg_func)\n",
    "    agg_view = grouped.xs(agg_func, axis=1, level=1)\n",
    "    display(agg_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bad453c7",
   "metadata": {
    "id": "bad453c7"
   },
   "outputs": [],
   "source": [
    "dataframes.to_csv(os.path.join(TIMESERIES_DATA_DIR, \"raw_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hkSc-_CdSxyZ",
   "metadata": {
    "id": "hkSc-_CdSxyZ"
   },
   "source": [
    "#### Log Scaling after checking for skewdness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "yNPu71utSxS2",
   "metadata": {
    "id": "yNPu71utSxS2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "def log_transform_if_skewed(df, columns, threshold=1.0):\n",
    "    \"\"\"\n",
    "    Log-transform the specified columns of a DataFrame based on their skewdness.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        columns (list): List of column names that need to be checked for skewdness.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with normalized columns.\n",
    "    \"\"\"\n",
    "    df_transformed = df.copy()\n",
    "\n",
    "    for col in columns:\n",
    "        # s = df[col].dropna()\n",
    "        s = df[col]\n",
    "        current_skewness = skew(s)\n",
    "\n",
    "        print(f\"[{col}] Skewness: {current_skewness:.2f}\")\n",
    "\n",
    "        if abs(current_skewness) > threshold:\n",
    "            # To avoid log(0) or log(negative values).\n",
    "            if (s <= 0).any():\n",
    "                shift = abs(s.min()) + 1e-6\n",
    "                print(f\"Applying log(x + {shift:.6f}) to {col}\")\n",
    "                df_transformed[col] = np.log(df[col] + shift)\n",
    "            else:\n",
    "                print(f\"Applying log(x) to {col}\")\n",
    "                df_transformed[col] = np.log(df[col])\n",
    "        else:\n",
    "            print(f\"No transformation applied to {col}.\")\n",
    "\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MeI64XXFXED8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "MeI64XXFXED8",
    "outputId": "35d8be00-8882-49ee-9ebc-f8b6845b919a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[no2] Skewness: 1.65\n",
      "Applying log(x + 2.544250) to no2\n",
      "[temp] Skewness: 0.21\n",
      "No transformation applied to temp.\n",
      "[o3] Skewness: 0.64\n",
      "No transformation applied to o3.\n",
      "[no] Skewness: 8.52\n",
      "Applying log(x + 3.360429) to no\n",
      "[press] Skewness: -9.34\n",
      "Applying log(x + 0.000001) to press\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>station_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>o3</th>\n",
       "      <th>no2</th>\n",
       "      <th>no</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681240</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933836</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-15.85</td>\n",
       "      <td>-13.815511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681241</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933836</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-16.35</td>\n",
       "      <td>-13.815511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681242</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933836</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-16.45</td>\n",
       "      <td>-13.815511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681243</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933836</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-17.15</td>\n",
       "      <td>-13.815511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681244</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933836</td>\n",
       "      <td>1.212069</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>-13.815511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        longitude   latitude station_code                  datetime   o3  \\\n",
       "681240   6.093923  50.754704      DENW094 1997-01-01 00:00:00+00:00  0.0   \n",
       "681241   6.093923  50.754704      DENW094 1997-01-01 01:00:00+00:00  0.0   \n",
       "681242   6.093923  50.754704      DENW094 1997-01-01 02:00:00+00:00  0.0   \n",
       "681243   6.093923  50.754704      DENW094 1997-01-01 03:00:00+00:00  0.0   \n",
       "681244   6.093923  50.754704      DENW094 1997-01-01 04:00:00+00:00  0.0   \n",
       "\n",
       "             no2        no   temp      press  \n",
       "681240  0.933836  1.212069 -15.85 -13.815511  \n",
       "681241  0.933836  1.212069 -16.35 -13.815511  \n",
       "681242  0.933836  1.212069 -16.45 -13.815511  \n",
       "681243  0.933836  1.212069 -17.15 -13.815511  \n",
       "681244  0.933836  1.212069 -17.35 -13.815511  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_= log_transform_if_skewed(dataframes, variable_columns, threshold=1.0)\n",
    "dataframe_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ojsWf0KrRyjr",
   "metadata": {
    "id": "ojsWf0KrRyjr"
   },
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z7XAF2WzcI5G",
   "metadata": {
    "id": "z7XAF2WzcI5G"
   },
   "source": [
    "ðŸ˜ˆ Task 8: Why do we need both log transformation and Z-score normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d2c0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(df, columns):\n",
    "    \"\"\"\n",
    "    Standardize the specified columns of a DataFrame by subtracting the mean\n",
    "    and dividing by the standard deviation (Z-score normalization).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        columns (list): List of column names to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with normalized columns.\n",
    "    \"\"\"\n",
    "    df_scaled = df.copy()\n",
    "    for col in columns:\n",
    "        mean = df_scaled[col].mean()\n",
    "        std = df_scaled[col].std()\n",
    "        df_scaled[col] = (df_scaled[col] - mean) / std\n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6kGKgXpsRzgk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6kGKgXpsRzgk",
    "outputId": "6c98c637-07d8-4f7f-cf4d-772ff4c21ce5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>station_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>o3</th>\n",
       "      <th>no2</th>\n",
       "      <th>no</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681240</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.566220</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681241</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.633418</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681242</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.646857</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681243</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.740934</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681244</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.767813</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        longitude   latitude station_code                  datetime        o3  \\\n",
       "681240   6.093923  50.754704      DENW094 1997-01-01 00:00:00+00:00 -1.686509   \n",
       "681241   6.093923  50.754704      DENW094 1997-01-01 01:00:00+00:00 -1.686509   \n",
       "681242   6.093923  50.754704      DENW094 1997-01-01 02:00:00+00:00 -1.686509   \n",
       "681243   6.093923  50.754704      DENW094 1997-01-01 03:00:00+00:00 -1.686509   \n",
       "681244   6.093923  50.754704      DENW094 1997-01-01 04:00:00+00:00 -1.686509   \n",
       "\n",
       "             no2        no      temp       press  \n",
       "681240 -2.140763 -0.758096 -3.566220 -337.675195  \n",
       "681241 -2.140763 -0.758096 -3.633418 -337.675195  \n",
       "681242 -2.140763 -0.758096 -3.646857 -337.675195  \n",
       "681243 -2.140763 -0.758096 -3.740934 -337.675195  \n",
       "681244 -2.140763 -0.758096 -3.767813 -337.675195  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = standard_scaler(dataframe_, variable_columns)\n",
    "dataframes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-cc-ixdbc_QR",
   "metadata": {
    "id": "-cc-ixdbc_QR"
   },
   "source": [
    "##### Save the normalized dataframe for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "Oi3PPzzJZ5Vf",
   "metadata": {
    "id": "Oi3PPzzJZ5Vf"
   },
   "outputs": [],
   "source": [
    "dataframes.to_csv(os.path.join(TIMESERIES_DATA_DIR, \"normalized_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZBg-E2YQert8",
   "metadata": {
    "id": "ZBg-E2YQert8"
   },
   "source": [
    "##### If you want the normalized data directly, then you could just download from the drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rZ4sHWj0c5ks",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rZ4sHWj0c5ks",
    "outputId": "9e0df20d-c721-4648-a46b-5f95c96c6fa2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>station_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>o3</th>\n",
       "      <th>no2</th>\n",
       "      <th>no</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.566220</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.633418</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.646857</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.740934</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.093923</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>-1.686509</td>\n",
       "      <td>-2.140763</td>\n",
       "      <td>-0.758096</td>\n",
       "      <td>-3.767813</td>\n",
       "      <td>-337.675195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude   latitude station_code                   datetime        o3  \\\n",
       "0   6.093923  50.754704      DENW094  1997-01-01 00:00:00+00:00 -1.686509   \n",
       "1   6.093923  50.754704      DENW094  1997-01-01 01:00:00+00:00 -1.686509   \n",
       "2   6.093923  50.754704      DENW094  1997-01-01 02:00:00+00:00 -1.686509   \n",
       "3   6.093923  50.754704      DENW094  1997-01-01 03:00:00+00:00 -1.686509   \n",
       "4   6.093923  50.754704      DENW094  1997-01-01 04:00:00+00:00 -1.686509   \n",
       "\n",
       "        no2        no      temp       press  \n",
       "0 -2.140763 -0.758096 -3.566220 -337.675195  \n",
       "1 -2.140763 -0.758096 -3.633418 -337.675195  \n",
       "2 -2.140763 -0.758096 -3.646857 -337.675195  \n",
       "3 -2.140763 -0.758096 -3.740934 -337.675195  \n",
       "4 -2.140763 -0.758096 -3.767813 -337.675195  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## Normalized data csv is also made available for the select stations in URL:\n",
    "# url = \"https://drive.google.com/uc?export=download&id=16Mjahl_vSznbXUFeD80xNbsz2eFmCeLG\"\n",
    "# dataframes = pd.read_csv(url)\n",
    "## Else if using local files you can load from the path as below:\n",
    "# e.g. r\"./content/timeseries_multivariate_data/normalized_data.csv\"\n",
    "dataframes = pd.read_csv(os.path.join(TIMESERIES_DATA_DIR, \"normalized_data.csv\"))\n",
    "dataframes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3tHSnChQeO-L",
   "metadata": {
    "id": "3tHSnChQeO-L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2588a2f2",
    "7426db96"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
